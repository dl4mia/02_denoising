{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise2Noise\n",
    "\n",
    "CARE network you trained in part 1 require that you acquire additional data for the purpose of denoising. For CARE we used a paired acquisition with high SNR, for Noise2Noise we had paired noisy acquisitions.\n",
    "\n",
    "This notebook uses a set of images with different levels of noise from SEM dataset.\n",
    "\n",
    "We'll use the [Careamics](https://careamics.github.io) library\n",
    "\n",
    "## Reference\n",
    "\n",
    "Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala, Timo Aila \n",
    "[Noise2Noise: Learning Image Restoration without Clean Data](https://arxiv.org/abs/1803.04189)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mandatory actions\n",
    "<div class=\"alert alert-danger\">\n",
    "Set your python kernel to <code>regression</code> <br>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h3>Task 2.2: Bla</h3>\n",
    "    \n",
    "This notebook uses a single image from the SEM data from the Noise2Noise notebook.\n",
    "\n",
    "If you brought your own raw data, use that instead! The only requirement is that the noise in your data is pixel-independent and zero-mean. If you're unsure whether your data fulfills that requirement or you don't yet understand why it is necessary ask one of us to discuss!\n",
    "\n",
    "If you don't have suitable data of your own, feel free to find some online or ask your fellow course participants. You can however also stick with the SEM data provided here and compare the results to what you achieved with Noise2Noise in the previous part.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\"><div class=\"alert alert-block alert-success\"><h1>Checkpoint 1</h1>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "from careamics_portfolio import PortfolioManager\n",
    "\n",
    "from careamics import CAREamist\n",
    "from careamics.config import create_n2n_configuration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Prepare the data\n",
    "\n",
    "SEM dataset consists of EM images with 7 different levels on noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files\n",
    "portfolio = PortfolioManager()\n",
    "root_path = Path(\"./data\")\n",
    "files = portfolio.denoising.N2N_SEM.download(root_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training data\n",
    "\n",
    "In this cell we can see the different levels of noise in the SEM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "train_image = tifffile.imread(root_path / \"denoising-N2N_SEM.unzip/SEM/train.tif\")\n",
    "print(f\"Train image shape: {train_image.shape}\")\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "ax[0].imshow(train_image[0], cmap=\"gray\")\n",
    "ax[0].set_title(\"Train image highest noise level\")\n",
    "ax[1].imshow(train_image[-1], cmap=\"gray\")\n",
    "ax[1].set_title(\"Train image lowest noise level\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zoom\n",
    "The noise level is hard to see at this zoom level. Let's also look at a smaller crop of them! Play around with this until you have a feeling for what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = tifffile.imread(files[0])\n",
    "print(f\"Train image shape: {train_image.shape}\")\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "ax[0].imshow(train_image[0,100:356, 500:756], cmap=\"gray\")\n",
    "ax[0].set_title(\"Train image highest noise level\")\n",
    "ax[1].imshow(train_image[-1, 100:356, 500:756], cmap=\"gray\")\n",
    "ax[1].set_title(\"Train image lowest noise level\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Create configuraion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = create_n2n_configuration(\n",
    "    experiment_name=\"LevitatingFrog\",\n",
    "    data_type=\"array\",\n",
    "    axes=\"YX\",\n",
    "    patch_size=[128, 128],\n",
    "    batch_size=128,\n",
    "    num_epochs=30,\n",
    "    logger=\"tensorboard\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training configuration\n",
    "print(training_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Model\n",
    "\n",
    "Create a Pytorch Lightning module\n",
    "\n",
    "Please take as look at the [documentation](https://careamics.github.io) to see the full list of parameters and configuration options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = CAREamist(source=training_config)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Run training \n",
    "\n",
    "We need to specify the paths to training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.train(train_source=train_image[0],\n",
    "            train_target=train_image[4],\n",
    "            val_source=train_image[0],\n",
    "            val_target=train_image[4]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4. Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "test_image = tifffile.imread(root_path / \"denoising-N2N_SEM.unzip/SEM/test.tif\")\n",
    "print(f\"Test image shape: {train_image.shape}\")\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "ax[0].imshow(test_image[0], cmap=\"gray\")\n",
    "ax[0].set_title(\"Test image highest noise level\")\n",
    "ax[1].imshow(test_image[-1], cmap=\"gray\")\n",
    "ax[1].set_title(\"Test image lowest noise level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = engine.predict(source=test_image[4], tile_size=(256, 256))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "ax[0].imshow(test_image[-1], cmap=\"gray\")\n",
    "ax[0].set_title(\"Test image lowest noise level\")\n",
    "ax[1].imshow(prediction, cmap=\"gray\")\n",
    "ax[1].set_title(\"Test image highest noise level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmcs_l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
